{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### connect to the elasticsearch server\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "import minio\n",
    "from minio.error import S3Error\n",
    "from minio.commonconfig import ENABLED\n",
    "from minio.versioningconfig import VersioningConfig\n",
    "\n",
    "from minio_utils import *\n",
    "\n",
    "##### input args\n",
    "path_to_main_input = \"./examples/dummy_data\"    \n",
    "minio_credential = \"credentials.macstudio.json\"\n",
    "es_credential = \"es_credential.json\"\n",
    "\n",
    "file_type = \"bam\"\n",
    "input_files = [item for item in pathlib.Path(os.path.join(path_to_main_input, file_type)).glob(\"*.{}\".format(file_type))]\n",
    "input_metadata = pd.DataFrame(data = [item.name for item in input_files], columns = [\"FileName\"])\n",
    "input_metadata[\"FileType\"] = file_type\n",
    "input_metadata[\"Labcode\"] = input_metadata[\"FileName\"].apply(lambda x: x.replace(\".{}\".format(file_type), \"\"))\n",
    "input_metadata[\"path\"] = [\"./examples/dummy_data/{}/{}.{}\".format(file_type, labcode, file_type) for labcode in input_metadata.Labcode.values]\n",
    "input_metadata[\"project\"] = \"ECD\"\n",
    "input_metadata[\"sub_project\"] = \"ECD_read_based\"\n",
    "input_metadata[\"Date\"] = datetime.now()\n",
    "input_metadata[\"pipeline\"] = \"bismark_wgbs\"\n",
    "input_metadata = input_metadata.set_index(\"path\")\n",
    "input_metadata_dict = input_metadata.to_dict(orient = \"index\") # the input metadata is ready to be added to the database elasticsearch\n",
    "\n",
    "class RDSBucket:\n",
    "    def __init__(self, \n",
    "                 minio_credential, \n",
    "                 bucketName, \n",
    "                 dataProfile,\n",
    "                 es_credential, \n",
    "                 versioning = True, \n",
    "                 verbose = False):\n",
    "        ##### minio client\n",
    "        self.minio_credential = minio_credential\n",
    "        self.es_credential = es_credential\n",
    "        self.bucketName = bucketName\n",
    "        self.dataProfile = dataProfile\n",
    "        self.versioning = versioning\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        ##### elasticsearch client\n",
    "        with open(self.es_credential, 'r') as file:\n",
    "            keys = json.load(file)\n",
    "            \n",
    "        self.es = Elasticsearch(\n",
    "            \"http://localhost:9200\", # deployed locally, no cloud\n",
    "            basic_auth=(keys[\"username\"], keys[\"password\"])) \n",
    "        client_info = self.es.info()\n",
    "        tmp = self.es.cat.indices(index='*', h='index', s='index:asc', format='json')\n",
    "        self.all_ES_indices = [index['index'] for index in tmp if index['index'][0] != \".\"] # not show hidden indice\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Connected to Elasticsearch!')\n",
    "            pprint(client_info.body)\n",
    "            \n",
    "        ##### RUN\n",
    "        with open(self.minio_credential, 'r') as file:\n",
    "            keys = json.load(file)\n",
    "        \n",
    "        minio_client = minio.Minio(\n",
    "            endpoint=\"localhost:9000\",\n",
    "            access_key=keys[\"accessKey\"],\n",
    "            secret_key=keys[\"secretKey\"],\n",
    "            secure=False \n",
    "        )\n",
    "        self.minio_client = minio_client\n",
    "        \n",
    "    def initBucket(self):\n",
    "        ##### initialize a new bucket\n",
    "        try:\n",
    "            # Check if the bucket already exists\n",
    "            exists = self.minio_client.bucket_exists(self.bucketName)\n",
    "            if exists == False: \n",
    "                # Make a new bucket\n",
    "                self.minio_client.make_bucket(self.bucketName)\n",
    "                print(f\"Bucket '{self.bucketName}' created successfully.\")\n",
    "                if self.versioning:\n",
    "                    self.minio_client.set_bucket_versioning(self.bucketName, VersioningConfig(ENABLED))\n",
    "\n",
    "            else:\n",
    "                print(f\"Bucket '{self.bucketName}' already exists. Cannot create bucket with the same name. Please choose another name\")\n",
    "            return True\n",
    "        except S3Error as e:\n",
    "            print(f\"Error creating bucket: {e}\")\n",
    "            return False\n",
    "        \n",
    "    def upload_file_to_bucket(self, path_to_file, object_name, file_metadata):\n",
    "        ##### add bucket name to the file metadata\n",
    "        file_metadata = {**file_metadata, **{\"bucket\": self.bucketName}}\n",
    "        ##### check if the file_metadata match the bucket's dataProfile\n",
    "        if list(file_metadata.keys()) == [list(item.keys()) for item in self.dataProfile.values()][0]:\n",
    "            try:\n",
    "                with open(path_to_file, 'rb') as file_data:\n",
    "                    file_stat = os.stat(path_to_file)\n",
    "                    self.minio_client.put_object(\n",
    "                        bucket_name=self.bucketName,\n",
    "                        object_name=object_name,\n",
    "                        data=file_data,\n",
    "                        length=file_stat.st_size,\n",
    "                        metadata=file_metadata\n",
    "                    )\n",
    "                if self.verbose:\n",
    "                    print(f\"File '{object_name}' uploaded successfully with metadata.\")\n",
    "                \n",
    "                ##### if file upload successfully, add the metadata to the elasticsearch database\n",
    "                if self.bucketName in self.all_ES_indices == False:\n",
    "                    self.es.indices.create(index = self.bucketName,  mappings = self.dataProfile)\n",
    "                self.es.index(index = self.bucketName, body = file_metadata)\n",
    "                return True\n",
    "            except S3Error as e:\n",
    "                print(f\"Error uploading file: {e}\")\n",
    "                return False\n",
    "        else:\n",
    "            raise ValueError(\"Cannot upload file. The file metadata does not match the bucket's data profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_profile = bam_profile = {\n",
    "    \"properties\": {\n",
    "        \"Labcode\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"SequencingID\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"FileName\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"FileType\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"Date\": {\n",
    "            \"type\": \"date\"\n",
    "        },\n",
    "        \"pipeline\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"project\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"sub_project\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"ref_genome\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"bucket\": {\n",
    "            \"type\": \"text\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "bamBucket = RDSBucket( \n",
    "                      minio_credential = minio_credential, \n",
    "                      bucketName = \"bam\", \n",
    "                      dataProfile = bam_profile,\n",
    "                      es_credential = es_credential, \n",
    "                      versioning = True, \n",
    "                      verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'bam' created successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bamBucket.initBucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The file metadata does not match the bucket's data profile",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./examples/dummy_data/bam/Yas662.bam\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      2\u001b[0m file_metadata \u001b[38;5;241m=\u001b[39m input_metadata_dict[path]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbamBucket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file_to_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFileName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfile_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 127\u001b[0m, in \u001b[0;36mRDSBucket.upload_file_to_bucket\u001b[0;34m(self, path_to_file, object_name, file_metadata)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file metadata does not match the bucket\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms data profile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The file metadata does not match the bucket's data profile"
     ]
    }
   ],
   "source": [
    "path = './examples/dummy_data/bam/Yas662.bam' \n",
    "file_metadata = input_metadata_dict[path]\n",
    "bamBucket.upload_file_to_bucket(path_to_file = path, \n",
    "                                object_name= [\"FileName\"], \n",
    "                                file_metadata = file_metadata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minio_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
